from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.options import Options
import csv
import time

# Setup Chrome
chrome_options = Options()
chrome_options.add_argument("--start-maximized")
chrome_options.add_argument("user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36")

driver = webdriver.Chrome(options=chrome_options)
all_products = []

print("Starting scraper...\n")

# Go to Amazon India search for face cream
driver.get("https://www.amazon.in/s?k=face+cream")
time.sleep(4)

# Scrape 2 pages
for page_num in range(1, 3):
    print(f"Scraping Page {page_num}...")
    time.sleep(3)
    
    # Find all products
     
    for product in products:
        # Product Name
        name_elements = product.find_elements(By.CSS_SELECTOR, "h2 span")
        name = name_elements[0].text if name_elements else "N/A"
        
        # Selling Price
        price_elements = product.find_elements(By.CSS_SELECTOR, "span.a-price-whole")
        selling_price = price_elements[0].text if price_elements else "N/A"
        
        # Discount Percentage
        discount_elements = product.find_elements(By.CSS_SELECTOR, "span.a-letter-space + span")
        discount = discount_elements[0].text if discount_elements else "N/A"
        
        # Monthly Purchases (1K+ bought in past month)
        purchase_elements = product.find_elements(By.CSS_SELECTOR, "span.a-size-base.a-color-secondary")
        monthly_purchases = "N/A"
        for elem in purchase_elements:
            text = elem.text
            if "bought" in text.lower() or "k+" in text.lower():
                monthly_purchases = text
                break
        
        # Save data (only if name exists)
        if name != "N/A":
            product_data = {
                'Product Name': name,
                'Selling Price': selling_price,
                'Discount': discount,
                'Monthly Purchases': monthly_purchases,
                'Page Number': page_num
            }
            all_products.append(product_data)
    
    # Go to next page
    if page_num < 2:
        next_button = driver.find_elements(By.CSS_SELECTOR, "a.s-pagination-next")
        if next_button:
            next_button[0].click()
            time.sleep(3)
        else:
            print("Cannot find next page button")
            break

# Save to CSV
print(f"\nTotal products scraped: {len(all_products)}")
print("Saving to CSV...")

csv_filename = 'amazon_face_cream.csv'
with open(csv_filename, 'w', newline='', encoding='utf-8') as file:
    fieldnames = ['Product Name', 'Selling Price', 'Discount', 'Monthly Purchases', 'Page Number']
    writer = csv.DictWriter(file, fieldnames=fieldnames)
    writer.writeheader()
    writer.writerows(all_products)

print(f"âœ“ Saved to {csv_filename}")

time.sleep(3)
driver.quit()
print("Done!")
